{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://www.datacamp.com/courses/machine-learning-with-tree-based-models-in-python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)\n",
    "text = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = soup.findAll('h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Learn',\n",
       " 'Pricing',\n",
       " 'Plans',\n",
       " 'Courses',\n",
       " 'Tracks',\n",
       " 'Instructors',\n",
       " 'Decision tree for classification',\n",
       " 'Train your first classification tree',\n",
       " 'Evaluate the classification tree',\n",
       " 'Logistic regression vs classification tree',\n",
       " 'Classification tree Learning',\n",
       " 'Growing a classification tree',\n",
       " 'Using entropy as a criterion',\n",
       " 'Entropy vs Gini index',\n",
       " 'Decision tree for regression',\n",
       " 'Train your first regression tree',\n",
       " 'Evaluate the regression tree',\n",
       " 'Linear regression vs regression tree',\n",
       " 'Bagging',\n",
       " 'Define the bagging classifier',\n",
       " 'Evaluate Bagging performance',\n",
       " 'Out of Bag Evaluation',\n",
       " 'Prepare the ground',\n",
       " 'OOB Score vs Test Set Score',\n",
       " 'Random Forests (RF)',\n",
       " 'Train an RF regressor',\n",
       " 'Evaluate the RF regressor',\n",
       " 'Visualizing features importances',\n",
       " \"Tuning a CART's Hyperprameters\",\n",
       " 'Tree hyperparameters',\n",
       " \"Set the tree's hyperparameter grid\",\n",
       " 'Search for the optimal tree',\n",
       " 'Evaluate the optimal tree',\n",
       " \"Tuning a RF's Hyperparameters\",\n",
       " 'Random forests hyperparameters',\n",
       " 'Set the hyperparameter grid of RF',\n",
       " 'Search for the optimal forest',\n",
       " 'Evaluate the optimal forest',\n",
       " 'Congratulations!',\n",
       " 'Generalization Error',\n",
       " 'Complexity, bias and variance',\n",
       " 'Overfitting and underfitting',\n",
       " 'Diagnose bias and variance problems',\n",
       " 'Instantiate the model',\n",
       " 'Evaluate the 10-fold CV error',\n",
       " 'Evaluate the training error',\n",
       " 'High bias or high variance?',\n",
       " 'Ensemble Learning',\n",
       " 'Define the ensemble',\n",
       " 'Evaluate individual classifiers',\n",
       " 'Better performance with a Voting Classifier',\n",
       " 'Adaboost',\n",
       " 'Define the AdaBoost classifier',\n",
       " 'Train the AdaBoost classifier',\n",
       " 'Evaluate the AdaBoost classifier',\n",
       " 'Gradient Boosting (GB)',\n",
       " 'Define the GB regressor',\n",
       " 'Train the GB regressor',\n",
       " 'Evaluate the GB regressor',\n",
       " 'Stochastic Gradient Boosting (SGB)',\n",
       " 'Regression with SGB',\n",
       " 'Train the SGB regressor',\n",
       " 'Evaluate the SGB regressor',\n",
       " 'Decision tree for classification',\n",
       " 'Train your first classification tree',\n",
       " 'Evaluate the classification tree',\n",
       " 'Logistic regression vs classification tree',\n",
       " 'Classification tree Learning',\n",
       " 'Growing a classification tree',\n",
       " 'Using entropy as a criterion',\n",
       " 'Entropy vs Gini index',\n",
       " 'Decision tree for regression',\n",
       " 'Train your first regression tree',\n",
       " 'Evaluate the regression tree',\n",
       " 'Linear regression vs regression tree',\n",
       " 'Generalization Error',\n",
       " 'Complexity, bias and variance',\n",
       " 'Overfitting and underfitting',\n",
       " 'Diagnose bias and variance problems',\n",
       " 'Instantiate the model',\n",
       " 'Evaluate the 10-fold CV error',\n",
       " 'Evaluate the training error',\n",
       " 'High bias or high variance?',\n",
       " 'Ensemble Learning',\n",
       " 'Define the ensemble',\n",
       " 'Evaluate individual classifiers',\n",
       " 'Better performance with a Voting Classifier',\n",
       " 'Bagging',\n",
       " 'Define the bagging classifier',\n",
       " 'Evaluate Bagging performance',\n",
       " 'Out of Bag Evaluation',\n",
       " 'Prepare the ground',\n",
       " 'OOB Score vs Test Set Score',\n",
       " 'Random Forests (RF)',\n",
       " 'Train an RF regressor',\n",
       " 'Evaluate the RF regressor',\n",
       " 'Visualizing features importances',\n",
       " 'Adaboost',\n",
       " 'Define the AdaBoost classifier',\n",
       " 'Train the AdaBoost classifier',\n",
       " 'Evaluate the AdaBoost classifier',\n",
       " 'Gradient Boosting (GB)',\n",
       " 'Define the GB regressor',\n",
       " 'Train the GB regressor',\n",
       " 'Evaluate the GB regressor',\n",
       " 'Stochastic Gradient Boosting (SGB)',\n",
       " 'Regression with SGB',\n",
       " 'Train the SGB regressor',\n",
       " 'Evaluate the SGB regressor',\n",
       " \"Tuning a CART's Hyperprameters\",\n",
       " 'Tree hyperparameters',\n",
       " \"Set the tree's hyperparameter grid\",\n",
       " 'Search for the optimal tree',\n",
       " 'Evaluate the optimal tree',\n",
       " \"Tuning a RF's Hyperparameters\",\n",
       " 'Random forests hyperparameters',\n",
       " 'Set the hyperparameter grid of RF',\n",
       " 'Search for the optimal forest',\n",
       " 'Evaluate the optimal forest',\n",
       " 'Congratulations!',\n",
       " 'Elie Kawerk',\n",
       " 'Tracks',\n",
       " 'Collaborators',\n",
       " 'Prerequisites',\n",
       " 'Datasets']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_list =[i.text for i in tag]\n",
    "sub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list= ['Decision tree for classification',\n",
    " 'Train your first classification tree',\n",
    " 'Evaluate the classification tree',\n",
    " 'Logistic regression vs classification tree',\n",
    " 'Classification tree Learning',\n",
    " 'Growing a classification tree',\n",
    " 'Using entropy as a criterion',\n",
    " 'Entropy vs Gini index',\n",
    " 'Decision tree for regression',\n",
    " 'Train your first regression tree',\n",
    " 'Evaluate the regression tree',\n",
    " 'Linear regression vs regression tree',\n",
    " 'Bagging',\n",
    " 'Define the bagging classifier',\n",
    " 'Evaluate Bagging performance',\n",
    " 'Out of Bag Evaluation',\n",
    " 'Prepare the ground',\n",
    " 'OOB Score vs Test Set Score',\n",
    " 'Random Forests (RF)',\n",
    " 'Train an RF regressor',\n",
    " 'Evaluate the RF regressor',\n",
    " 'Visualizing features importances',\n",
    " \"Tuning a CART's Hyperprameters\",\n",
    " 'Tree hyperparameters',\n",
    " \"Set the tree's hyperparameter grid\",\n",
    " 'Search for the optimal tree',\n",
    " 'Evaluate the optimal tree',\n",
    " \"Tuning a RF's Hyperparameters\",\n",
    " 'Random forests hyperparameters',\n",
    " 'Set the hyperparameter grid of RF',\n",
    " 'Search for the optimal forest',\n",
    " 'Evaluate the optimal forest',\n",
    " 'Congratulations!',\n",
    " 'Generalization Error',\n",
    " 'Complexity, bias and variance',\n",
    " 'Overfitting and underfitting',\n",
    " 'Diagnose bias and variance problems',\n",
    " 'Instantiate the model',\n",
    " 'Evaluate the 10-fold CV error',\n",
    " 'Evaluate the training error',\n",
    " 'High bias or high variance?',\n",
    " 'Ensemble Learning',\n",
    " 'Define the ensemble',\n",
    " 'Evaluate individual classifiers',\n",
    " 'Better performance with a Voting Classifier',\n",
    " 'Adaboost',\n",
    " 'Define the AdaBoost classifier',\n",
    " 'Train the AdaBoost classifier',\n",
    " 'Evaluate the AdaBoost classifier',\n",
    " 'Gradient Boosting (GB)',\n",
    " 'Define the GB regressor',\n",
    " 'Train the GB regressor',\n",
    " 'Evaluate the GB regressor',\n",
    " 'Stochastic Gradient Boosting (SGB)',\n",
    " 'Regression with SGB',\n",
    " 'Train the SGB regressor',\n",
    " 'Evaluate the SGB regressor',\n",
    " 'Decision tree for classification',\n",
    " 'Train your first classification tree',\n",
    " 'Evaluate the classification tree',\n",
    " 'Logistic regression vs classification tree',\n",
    " 'Classification tree Learning',\n",
    " 'Growing a classification tree',\n",
    " 'Using entropy as a criterion',\n",
    " 'Entropy vs Gini index',\n",
    " 'Decision tree for regression',\n",
    " 'Train your first regression tree',\n",
    " 'Evaluate the regression tree',\n",
    " 'Linear regression vs regression tree',\n",
    " 'Generalization Error',\n",
    " 'Complexity, bias and variance',\n",
    " 'Overfitting and underfitting',\n",
    " 'Diagnose bias and variance problems',\n",
    " 'Instantiate the model',\n",
    " 'Evaluate the 10-fold CV error',\n",
    " 'Evaluate the training error',\n",
    " 'High bias or high variance?',\n",
    " 'Ensemble Learning',\n",
    " 'Define the ensemble',\n",
    " 'Evaluate individual classifiers',\n",
    " 'Better performance with a Voting Classifier',\n",
    " 'Bagging',\n",
    " 'Define the bagging classifier',\n",
    " 'Evaluate Bagging performance',\n",
    " 'Out of Bag Evaluation',\n",
    " 'Prepare the ground',\n",
    " 'OOB Score vs Test Set Score',\n",
    " 'Random Forests (RF)',\n",
    " 'Train an RF regressor',\n",
    " 'Evaluate the RF regressor',\n",
    " 'Visualizing features importances',\n",
    " 'Adaboost',\n",
    " 'Define the AdaBoost classifier',\n",
    " 'Train the AdaBoost classifier',\n",
    " 'Evaluate the AdaBoost classifier',\n",
    " 'Gradient Boosting (GB)',\n",
    " 'Define the GB regressor',\n",
    " 'Train the GB regressor',\n",
    " 'Evaluate the GB regressor',\n",
    " 'Stochastic Gradient Boosting (SGB)',\n",
    " 'Regression with SGB',\n",
    " 'Train the SGB regressor',\n",
    " 'Evaluate the SGB regressor',\n",
    " \"Tuning a CART's Hyperprameters\",\n",
    " 'Tree hyperparameters',\n",
    " \"Set the tree's hyperparameter grid\",\n",
    " 'Search for the optimal tree',\n",
    " 'Evaluate the optimal tree',\n",
    " \"Tuning a RF's Hyperparameters\",\n",
    " 'Random forests hyperparameters',\n",
    " 'Set the hyperparameter grid of RF',\n",
    " 'Search for the optimal forest',\n",
    " 'Evaluate the optimal forest',\n",
    " 'Congratulations!']\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Dictionary for markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = []\n",
    "s2 = \"### \"\n",
    "for i in sub_list:\n",
    "    l1.append(s2+i)\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = []\n",
    "s1 = \"\\n<p id ='\"\n",
    "s2 = \"'><p>\\n\"\n",
    "for i in sub_list:\n",
    "    l2.append(s1+''.join([k[0] for k in i.split(' ')])+s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tuples=list(zip(l1, l2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = [list(elem) for elem in list_of_tuples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Decision tree for classification \n",
      "<p id ='Dtfc'><p>\n",
      "\n",
      "### Train your first classification tree \n",
      "<p id ='Tyfct'><p>\n",
      "\n",
      "### Evaluate the classification tree \n",
      "<p id ='Etct'><p>\n",
      "\n",
      "### Logistic regression vs classification tree \n",
      "<p id ='Lrvct'><p>\n",
      "\n",
      "### Classification tree Learning \n",
      "<p id ='CtL'><p>\n",
      "\n",
      "### Growing a classification tree \n",
      "<p id ='Gact'><p>\n",
      "\n",
      "### Using entropy as a criterion \n",
      "<p id ='Ueaac'><p>\n",
      "\n",
      "### Entropy vs Gini index \n",
      "<p id ='EvGi'><p>\n",
      "\n",
      "### Decision tree for regression \n",
      "<p id ='Dtfr'><p>\n",
      "\n",
      "### Train your first regression tree \n",
      "<p id ='Tyfrt'><p>\n",
      "\n",
      "### Evaluate the regression tree \n",
      "<p id ='Etrt'><p>\n",
      "\n",
      "### Linear regression vs regression tree \n",
      "<p id ='Lrvrt'><p>\n",
      "\n",
      "### Bagging \n",
      "<p id ='B'><p>\n",
      "\n",
      "### Define the bagging classifier \n",
      "<p id ='Dtbc'><p>\n",
      "\n",
      "### Evaluate Bagging performance \n",
      "<p id ='EBp'><p>\n",
      "\n",
      "### Out of Bag Evaluation \n",
      "<p id ='OoBE'><p>\n",
      "\n",
      "### Prepare the ground \n",
      "<p id ='Ptg'><p>\n",
      "\n",
      "### OOB Score vs Test Set Score \n",
      "<p id ='OSvTSS'><p>\n",
      "\n",
      "### Random Forests (RF) \n",
      "<p id ='RF('><p>\n",
      "\n",
      "### Train an RF regressor \n",
      "<p id ='TaRr'><p>\n",
      "\n",
      "### Evaluate the RF regressor \n",
      "<p id ='EtRr'><p>\n",
      "\n",
      "### Visualizing features importances \n",
      "<p id ='Vfi'><p>\n",
      "\n",
      "### Tuning a CART's Hyperprameters \n",
      "<p id ='TaCH'><p>\n",
      "\n",
      "### Tree hyperparameters \n",
      "<p id ='Th'><p>\n",
      "\n",
      "### Set the tree's hyperparameter grid \n",
      "<p id ='Stthg'><p>\n",
      "\n",
      "### Search for the optimal tree \n",
      "<p id ='Sftot'><p>\n",
      "\n",
      "### Evaluate the optimal tree \n",
      "<p id ='Etot'><p>\n",
      "\n",
      "### Tuning a RF's Hyperparameters \n",
      "<p id ='TaRH'><p>\n",
      "\n",
      "### Random forests hyperparameters \n",
      "<p id ='Rfh'><p>\n",
      "\n",
      "### Set the hyperparameter grid of RF \n",
      "<p id ='SthgoR'><p>\n",
      "\n",
      "### Search for the optimal forest \n",
      "<p id ='Sftof'><p>\n",
      "\n",
      "### Evaluate the optimal forest \n",
      "<p id ='Etof'><p>\n",
      "\n",
      "### Congratulations! \n",
      "<p id ='C'><p>\n",
      "\n",
      "### Generalization Error \n",
      "<p id ='GE'><p>\n",
      "\n",
      "### Complexity, bias and variance \n",
      "<p id ='Cbav'><p>\n",
      "\n",
      "### Overfitting and underfitting \n",
      "<p id ='Oau'><p>\n",
      "\n",
      "### Diagnose bias and variance problems \n",
      "<p id ='Dbavp'><p>\n",
      "\n",
      "### Instantiate the model \n",
      "<p id ='Itm'><p>\n",
      "\n",
      "### Evaluate the 10-fold CV error \n",
      "<p id ='Et1Ce'><p>\n",
      "\n",
      "### Evaluate the training error \n",
      "<p id ='Ette'><p>\n",
      "\n",
      "### High bias or high variance? \n",
      "<p id ='Hbohv'><p>\n",
      "\n",
      "### Ensemble Learning \n",
      "<p id ='EL'><p>\n",
      "\n",
      "### Define the ensemble \n",
      "<p id ='Dte'><p>\n",
      "\n",
      "### Evaluate individual classifiers \n",
      "<p id ='Eic'><p>\n",
      "\n",
      "### Better performance with a Voting Classifier \n",
      "<p id ='BpwaVC'><p>\n",
      "\n",
      "### Adaboost \n",
      "<p id ='A'><p>\n",
      "\n",
      "### Define the AdaBoost classifier \n",
      "<p id ='DtAc'><p>\n",
      "\n",
      "### Train the AdaBoost classifier \n",
      "<p id ='TtAc'><p>\n",
      "\n",
      "### Evaluate the AdaBoost classifier \n",
      "<p id ='EtAc'><p>\n",
      "\n",
      "### Gradient Boosting (GB) \n",
      "<p id ='GB('><p>\n",
      "\n",
      "### Define the GB regressor \n",
      "<p id ='DtGr'><p>\n",
      "\n",
      "### Train the GB regressor \n",
      "<p id ='TtGr'><p>\n",
      "\n",
      "### Evaluate the GB regressor \n",
      "<p id ='EtGr'><p>\n",
      "\n",
      "### Stochastic Gradient Boosting (SGB) \n",
      "<p id ='SGB('><p>\n",
      "\n",
      "### Regression with SGB \n",
      "<p id ='RwS'><p>\n",
      "\n",
      "### Train the SGB regressor \n",
      "<p id ='TtSr'><p>\n",
      "\n",
      "### Evaluate the SGB regressor \n",
      "<p id ='EtSr'><p>\n",
      "\n",
      "### Decision tree for classification \n",
      "<p id ='Dtfc'><p>\n",
      "\n",
      "### Train your first classification tree \n",
      "<p id ='Tyfct'><p>\n",
      "\n",
      "### Evaluate the classification tree \n",
      "<p id ='Etct'><p>\n",
      "\n",
      "### Logistic regression vs classification tree \n",
      "<p id ='Lrvct'><p>\n",
      "\n",
      "### Classification tree Learning \n",
      "<p id ='CtL'><p>\n",
      "\n",
      "### Growing a classification tree \n",
      "<p id ='Gact'><p>\n",
      "\n",
      "### Using entropy as a criterion \n",
      "<p id ='Ueaac'><p>\n",
      "\n",
      "### Entropy vs Gini index \n",
      "<p id ='EvGi'><p>\n",
      "\n",
      "### Decision tree for regression \n",
      "<p id ='Dtfr'><p>\n",
      "\n",
      "### Train your first regression tree \n",
      "<p id ='Tyfrt'><p>\n",
      "\n",
      "### Evaluate the regression tree \n",
      "<p id ='Etrt'><p>\n",
      "\n",
      "### Linear regression vs regression tree \n",
      "<p id ='Lrvrt'><p>\n",
      "\n",
      "### Generalization Error \n",
      "<p id ='GE'><p>\n",
      "\n",
      "### Complexity, bias and variance \n",
      "<p id ='Cbav'><p>\n",
      "\n",
      "### Overfitting and underfitting \n",
      "<p id ='Oau'><p>\n",
      "\n",
      "### Diagnose bias and variance problems \n",
      "<p id ='Dbavp'><p>\n",
      "\n",
      "### Instantiate the model \n",
      "<p id ='Itm'><p>\n",
      "\n",
      "### Evaluate the 10-fold CV error \n",
      "<p id ='Et1Ce'><p>\n",
      "\n",
      "### Evaluate the training error \n",
      "<p id ='Ette'><p>\n",
      "\n",
      "### High bias or high variance? \n",
      "<p id ='Hbohv'><p>\n",
      "\n",
      "### Ensemble Learning \n",
      "<p id ='EL'><p>\n",
      "\n",
      "### Define the ensemble \n",
      "<p id ='Dte'><p>\n",
      "\n",
      "### Evaluate individual classifiers \n",
      "<p id ='Eic'><p>\n",
      "\n",
      "### Better performance with a Voting Classifier \n",
      "<p id ='BpwaVC'><p>\n",
      "\n",
      "### Bagging \n",
      "<p id ='B'><p>\n",
      "\n",
      "### Define the bagging classifier \n",
      "<p id ='Dtbc'><p>\n",
      "\n",
      "### Evaluate Bagging performance \n",
      "<p id ='EBp'><p>\n",
      "\n",
      "### Out of Bag Evaluation \n",
      "<p id ='OoBE'><p>\n",
      "\n",
      "### Prepare the ground \n",
      "<p id ='Ptg'><p>\n",
      "\n",
      "### OOB Score vs Test Set Score \n",
      "<p id ='OSvTSS'><p>\n",
      "\n",
      "### Random Forests (RF) \n",
      "<p id ='RF('><p>\n",
      "\n",
      "### Train an RF regressor \n",
      "<p id ='TaRr'><p>\n",
      "\n",
      "### Evaluate the RF regressor \n",
      "<p id ='EtRr'><p>\n",
      "\n",
      "### Visualizing features importances \n",
      "<p id ='Vfi'><p>\n",
      "\n",
      "### Adaboost \n",
      "<p id ='A'><p>\n",
      "\n",
      "### Define the AdaBoost classifier \n",
      "<p id ='DtAc'><p>\n",
      "\n",
      "### Train the AdaBoost classifier \n",
      "<p id ='TtAc'><p>\n",
      "\n",
      "### Evaluate the AdaBoost classifier \n",
      "<p id ='EtAc'><p>\n",
      "\n",
      "### Gradient Boosting (GB) \n",
      "<p id ='GB('><p>\n",
      "\n",
      "### Define the GB regressor \n",
      "<p id ='DtGr'><p>\n",
      "\n",
      "### Train the GB regressor \n",
      "<p id ='TtGr'><p>\n",
      "\n",
      "### Evaluate the GB regressor \n",
      "<p id ='EtGr'><p>\n",
      "\n",
      "### Stochastic Gradient Boosting (SGB) \n",
      "<p id ='SGB('><p>\n",
      "\n",
      "### Regression with SGB \n",
      "<p id ='RwS'><p>\n",
      "\n",
      "### Train the SGB regressor \n",
      "<p id ='TtSr'><p>\n",
      "\n",
      "### Evaluate the SGB regressor \n",
      "<p id ='EtSr'><p>\n",
      "\n",
      "### Tuning a CART's Hyperprameters \n",
      "<p id ='TaCH'><p>\n",
      "\n",
      "### Tree hyperparameters \n",
      "<p id ='Th'><p>\n",
      "\n",
      "### Set the tree's hyperparameter grid \n",
      "<p id ='Stthg'><p>\n",
      "\n",
      "### Search for the optimal tree \n",
      "<p id ='Sftot'><p>\n",
      "\n",
      "### Evaluate the optimal tree \n",
      "<p id ='Etot'><p>\n",
      "\n",
      "### Tuning a RF's Hyperparameters \n",
      "<p id ='TaRH'><p>\n",
      "\n",
      "### Random forests hyperparameters \n",
      "<p id ='Rfh'><p>\n",
      "\n",
      "### Set the hyperparameter grid of RF \n",
      "<p id ='SthgoR'><p>\n",
      "\n",
      "### Search for the optimal forest \n",
      "<p id ='Sftof'><p>\n",
      "\n",
      "### Evaluate the optimal forest \n",
      "<p id ='Etof'><p>\n",
      "\n",
      "### Congratulations! \n",
      "<p id ='C'><p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in list_of_lists:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict = []\n",
    "for i in list_of_lists:\n",
    "    list_dict.append({\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": i\n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to make Upper Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify(a):\n",
    "    s = ''\n",
    "    for i in a:\n",
    "    \n",
    "        s = s+'* ['+i+'](#'+ ''.join([k[0] for k in i.split(' ')])+')'+'\\n'\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretify header for markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Decision tree for classification](#Dtfc)\n",
      "* [Train your first classification tree](#Tyfct)\n",
      "* [Evaluate the classification tree](#Etct)\n",
      "* [Logistic regression vs classification tree](#Lrvct)\n",
      "* [Classification tree Learning](#CtL)\n",
      "* [Growing a classification tree](#Gact)\n",
      "* [Using entropy as a criterion](#Ueaac)\n",
      "* [Entropy vs Gini index](#EvGi)\n",
      "* [Decision tree for regression](#Dtfr)\n",
      "* [Train your first regression tree](#Tyfrt)\n",
      "* [Evaluate the regression tree](#Etrt)\n",
      "* [Linear regression vs regression tree](#Lrvrt)\n",
      "* [Bagging](#B)\n",
      "* [Define the bagging classifier](#Dtbc)\n",
      "* [Evaluate Bagging performance](#EBp)\n",
      "* [Out of Bag Evaluation](#OoBE)\n",
      "* [Prepare the ground](#Ptg)\n",
      "* [OOB Score vs Test Set Score](#OSvTSS)\n",
      "* [Random Forests (RF)](#RF()\n",
      "* [Train an RF regressor](#TaRr)\n",
      "* [Evaluate the RF regressor](#EtRr)\n",
      "* [Visualizing features importances](#Vfi)\n",
      "* [Tuning a CART's Hyperprameters](#TaCH)\n",
      "* [Tree hyperparameters](#Th)\n",
      "* [Set the tree's hyperparameter grid](#Stthg)\n",
      "* [Search for the optimal tree](#Sftot)\n",
      "* [Evaluate the optimal tree](#Etot)\n",
      "* [Tuning a RF's Hyperparameters](#TaRH)\n",
      "* [Random forests hyperparameters](#Rfh)\n",
      "* [Set the hyperparameter grid of RF](#SthgoR)\n",
      "* [Search for the optimal forest](#Sftof)\n",
      "* [Evaluate the optimal forest](#Etof)\n",
      "* [Congratulations!](#C)\n",
      "* [Generalization Error](#GE)\n",
      "* [Complexity, bias and variance](#Cbav)\n",
      "* [Overfitting and underfitting](#Oau)\n",
      "* [Diagnose bias and variance problems](#Dbavp)\n",
      "* [Instantiate the model](#Itm)\n",
      "* [Evaluate the 10-fold CV error](#Et1Ce)\n",
      "* [Evaluate the training error](#Ette)\n",
      "* [High bias or high variance?](#Hbohv)\n",
      "* [Ensemble Learning](#EL)\n",
      "* [Define the ensemble](#Dte)\n",
      "* [Evaluate individual classifiers](#Eic)\n",
      "* [Better performance with a Voting Classifier](#BpwaVC)\n",
      "* [Adaboost](#A)\n",
      "* [Define the AdaBoost classifier](#DtAc)\n",
      "* [Train the AdaBoost classifier](#TtAc)\n",
      "* [Evaluate the AdaBoost classifier](#EtAc)\n",
      "* [Gradient Boosting (GB)](#GB()\n",
      "* [Define the GB regressor](#DtGr)\n",
      "* [Train the GB regressor](#TtGr)\n",
      "* [Evaluate the GB regressor](#EtGr)\n",
      "* [Stochastic Gradient Boosting (SGB)](#SGB()\n",
      "* [Regression with SGB](#RwS)\n",
      "* [Train the SGB regressor](#TtSr)\n",
      "* [Evaluate the SGB regressor](#EtSr)\n",
      "* [Decision tree for classification](#Dtfc)\n",
      "* [Train your first classification tree](#Tyfct)\n",
      "* [Evaluate the classification tree](#Etct)\n",
      "* [Logistic regression vs classification tree](#Lrvct)\n",
      "* [Classification tree Learning](#CtL)\n",
      "* [Growing a classification tree](#Gact)\n",
      "* [Using entropy as a criterion](#Ueaac)\n",
      "* [Entropy vs Gini index](#EvGi)\n",
      "* [Decision tree for regression](#Dtfr)\n",
      "* [Train your first regression tree](#Tyfrt)\n",
      "* [Evaluate the regression tree](#Etrt)\n",
      "* [Linear regression vs regression tree](#Lrvrt)\n",
      "* [Generalization Error](#GE)\n",
      "* [Complexity, bias and variance](#Cbav)\n",
      "* [Overfitting and underfitting](#Oau)\n",
      "* [Diagnose bias and variance problems](#Dbavp)\n",
      "* [Instantiate the model](#Itm)\n",
      "* [Evaluate the 10-fold CV error](#Et1Ce)\n",
      "* [Evaluate the training error](#Ette)\n",
      "* [High bias or high variance?](#Hbohv)\n",
      "* [Ensemble Learning](#EL)\n",
      "* [Define the ensemble](#Dte)\n",
      "* [Evaluate individual classifiers](#Eic)\n",
      "* [Better performance with a Voting Classifier](#BpwaVC)\n",
      "* [Bagging](#B)\n",
      "* [Define the bagging classifier](#Dtbc)\n",
      "* [Evaluate Bagging performance](#EBp)\n",
      "* [Out of Bag Evaluation](#OoBE)\n",
      "* [Prepare the ground](#Ptg)\n",
      "* [OOB Score vs Test Set Score](#OSvTSS)\n",
      "* [Random Forests (RF)](#RF()\n",
      "* [Train an RF regressor](#TaRr)\n",
      "* [Evaluate the RF regressor](#EtRr)\n",
      "* [Visualizing features importances](#Vfi)\n",
      "* [Adaboost](#A)\n",
      "* [Define the AdaBoost classifier](#DtAc)\n",
      "* [Train the AdaBoost classifier](#TtAc)\n",
      "* [Evaluate the AdaBoost classifier](#EtAc)\n",
      "* [Gradient Boosting (GB)](#GB()\n",
      "* [Define the GB regressor](#DtGr)\n",
      "* [Train the GB regressor](#TtGr)\n",
      "* [Evaluate the GB regressor](#EtGr)\n",
      "* [Stochastic Gradient Boosting (SGB)](#SGB()\n",
      "* [Regression with SGB](#RwS)\n",
      "* [Train the SGB regressor](#TtSr)\n",
      "* [Evaluate the SGB regressor](#EtSr)\n",
      "* [Tuning a CART's Hyperprameters](#TaCH)\n",
      "* [Tree hyperparameters](#Th)\n",
      "* [Set the tree's hyperparameter grid](#Stthg)\n",
      "* [Search for the optimal tree](#Sftot)\n",
      "* [Evaluate the optimal tree](#Etot)\n",
      "* [Tuning a RF's Hyperparameters](#TaRH)\n",
      "* [Random forests hyperparameters](#Rfh)\n",
      "* [Set the hyperparameter grid of RF](#SthgoR)\n",
      "* [Search for the optimal forest](#Sftof)\n",
      "* [Evaluate the optimal forest](#Etof)\n",
      "* [Congratulations!](#C)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prettify(sub_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bunch of sub markdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Decision tree for classification', \"\\n<p id ='Dtfc'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Train your first classification tree',\n",
       "   \"\\n<p id ='Tyfct'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the classification tree', \"\\n<p id ='Etct'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Logistic regression vs classification tree',\n",
       "   \"\\n<p id ='Lrvct'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Classification tree Learning', \"\\n<p id ='CtL'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Growing a classification tree', \"\\n<p id ='Gact'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Using entropy as a criterion', \"\\n<p id ='Ueaac'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Entropy vs Gini index', \"\\n<p id ='EvGi'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Decision tree for regression', \"\\n<p id ='Dtfr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Train your first regression tree',\n",
       "   \"\\n<p id ='Tyfrt'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the regression tree', \"\\n<p id ='Etrt'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Linear regression vs regression tree',\n",
       "   \"\\n<p id ='Lrvrt'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Bagging', \"\\n<p id ='B'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Define the bagging classifier', \"\\n<p id ='Dtbc'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate Bagging performance', \"\\n<p id ='EBp'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Out of Bag Evaluation', \"\\n<p id ='OoBE'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Prepare the ground', \"\\n<p id ='Ptg'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### OOB Score vs Test Set Score', \"\\n<p id ='OSvTSS'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Random Forests (RF)', \"\\n<p id ='RF('><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Train an RF regressor', \"\\n<p id ='TaRr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the RF regressor', \"\\n<p id ='EtRr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Visualizing features importances', \"\\n<p id ='Vfi'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': [\"### Tuning a CART's Hyperprameters\", \"\\n<p id ='TaCH'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Tree hyperparameters', \"\\n<p id ='Th'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': [\"### Set the tree's hyperparameter grid\",\n",
       "   \"\\n<p id ='Stthg'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Search for the optimal tree', \"\\n<p id ='Sftot'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the optimal tree', \"\\n<p id ='Etot'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': [\"### Tuning a RF's Hyperparameters\", \"\\n<p id ='TaRH'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Random forests hyperparameters', \"\\n<p id ='Rfh'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Set the hyperparameter grid of RF',\n",
       "   \"\\n<p id ='SthgoR'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Search for the optimal forest', \"\\n<p id ='Sftof'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the optimal forest', \"\\n<p id ='Etof'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Congratulations!', \"\\n<p id ='C'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Generalization Error', \"\\n<p id ='GE'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Complexity, bias and variance', \"\\n<p id ='Cbav'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Overfitting and underfitting', \"\\n<p id ='Oau'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Diagnose bias and variance problems',\n",
       "   \"\\n<p id ='Dbavp'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Instantiate the model', \"\\n<p id ='Itm'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the 10-fold CV error', \"\\n<p id ='Et1Ce'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the training error', \"\\n<p id ='Ette'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### High bias or high variance?', \"\\n<p id ='Hbohv'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Ensemble Learning', \"\\n<p id ='EL'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Define the ensemble', \"\\n<p id ='Dte'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate individual classifiers', \"\\n<p id ='Eic'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Better performance with a Voting Classifier',\n",
       "   \"\\n<p id ='BpwaVC'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Adaboost', \"\\n<p id ='A'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Define the AdaBoost classifier', \"\\n<p id ='DtAc'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Train the AdaBoost classifier', \"\\n<p id ='TtAc'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the AdaBoost classifier', \"\\n<p id ='EtAc'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Gradient Boosting (GB)', \"\\n<p id ='GB('><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Define the GB regressor', \"\\n<p id ='DtGr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Train the GB regressor', \"\\n<p id ='TtGr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the GB regressor', \"\\n<p id ='EtGr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Stochastic Gradient Boosting (SGB)',\n",
       "   \"\\n<p id ='SGB('><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Regression with SGB', \"\\n<p id ='RwS'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Train the SGB regressor', \"\\n<p id ='TtSr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the SGB regressor', \"\\n<p id ='EtSr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Decision tree for classification', \"\\n<p id ='Dtfc'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Train your first classification tree',\n",
       "   \"\\n<p id ='Tyfct'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the classification tree', \"\\n<p id ='Etct'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Logistic regression vs classification tree',\n",
       "   \"\\n<p id ='Lrvct'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Classification tree Learning', \"\\n<p id ='CtL'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Growing a classification tree', \"\\n<p id ='Gact'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Using entropy as a criterion', \"\\n<p id ='Ueaac'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Entropy vs Gini index', \"\\n<p id ='EvGi'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Decision tree for regression', \"\\n<p id ='Dtfr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Train your first regression tree',\n",
       "   \"\\n<p id ='Tyfrt'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the regression tree', \"\\n<p id ='Etrt'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Linear regression vs regression tree',\n",
       "   \"\\n<p id ='Lrvrt'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Generalization Error', \"\\n<p id ='GE'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Complexity, bias and variance', \"\\n<p id ='Cbav'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Overfitting and underfitting', \"\\n<p id ='Oau'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Diagnose bias and variance problems',\n",
       "   \"\\n<p id ='Dbavp'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Instantiate the model', \"\\n<p id ='Itm'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the 10-fold CV error', \"\\n<p id ='Et1Ce'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the training error', \"\\n<p id ='Ette'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### High bias or high variance?', \"\\n<p id ='Hbohv'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Ensemble Learning', \"\\n<p id ='EL'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Define the ensemble', \"\\n<p id ='Dte'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate individual classifiers', \"\\n<p id ='Eic'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Better performance with a Voting Classifier',\n",
       "   \"\\n<p id ='BpwaVC'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Bagging', \"\\n<p id ='B'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Define the bagging classifier', \"\\n<p id ='Dtbc'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate Bagging performance', \"\\n<p id ='EBp'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Out of Bag Evaluation', \"\\n<p id ='OoBE'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Prepare the ground', \"\\n<p id ='Ptg'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### OOB Score vs Test Set Score', \"\\n<p id ='OSvTSS'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Random Forests (RF)', \"\\n<p id ='RF('><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Train an RF regressor', \"\\n<p id ='TaRr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the RF regressor', \"\\n<p id ='EtRr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Visualizing features importances', \"\\n<p id ='Vfi'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Adaboost', \"\\n<p id ='A'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Define the AdaBoost classifier', \"\\n<p id ='DtAc'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Train the AdaBoost classifier', \"\\n<p id ='TtAc'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the AdaBoost classifier', \"\\n<p id ='EtAc'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Gradient Boosting (GB)', \"\\n<p id ='GB('><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Define the GB regressor', \"\\n<p id ='DtGr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Train the GB regressor', \"\\n<p id ='TtGr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the GB regressor', \"\\n<p id ='EtGr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Stochastic Gradient Boosting (SGB)',\n",
       "   \"\\n<p id ='SGB('><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Regression with SGB', \"\\n<p id ='RwS'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Train the SGB regressor', \"\\n<p id ='TtSr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the SGB regressor', \"\\n<p id ='EtSr'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': [\"### Tuning a CART's Hyperprameters\", \"\\n<p id ='TaCH'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Tree hyperparameters', \"\\n<p id ='Th'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': [\"### Set the tree's hyperparameter grid\",\n",
       "   \"\\n<p id ='Stthg'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Search for the optimal tree', \"\\n<p id ='Sftot'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the optimal tree', \"\\n<p id ='Etot'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': [\"### Tuning a RF's Hyperparameters\", \"\\n<p id ='TaRH'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Random forests hyperparameters', \"\\n<p id ='Rfh'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Set the hyperparameter grid of RF',\n",
       "   \"\\n<p id ='SthgoR'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Search for the optimal forest', \"\\n<p id ='Sftof'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Evaluate the optimal forest', \"\\n<p id ='Etof'><p>\\n\"]},\n",
       " {'cell_type': 'markdown',\n",
       "  'metadata': {},\n",
       "  'source': ['### Congratulations!', \"\\n<p id ='C'><p>\\n\"]}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
